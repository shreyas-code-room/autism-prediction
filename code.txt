# import streamlit as st
# import joblib
# import numpy as np
# import pandas as pd
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.preprocessing import LabelEncoder
# from sklearn.impute import SimpleImputer
# from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report
# import plotly.graph_objects as go
# import plotly.express as px

# def load_model():
#     models = {
#         'Logistic Regression': joblib.load('logistic_regression_model.joblib'),
#         'XGBoost': joblib.load('xgboost_model.joblib'),
#         'SVM': joblib.load('svm_model.joblib')
#     }
#     feature_columns = joblib.load('feature_columns.joblib')
#     scaler = joblib.load('feature_scaler.joblib')
#     return models, feature_columns, scaler

# def preprocess_input(input_data, feature_columns, scaler):
#     # Create a dictionary to store processed input
#     processed_input = {}
    
#     # Explicitly handle each expected feature column
#     for col in feature_columns:
#         if col.startswith('A') and col.endswith('_Score'):
#             # Handle score columns
#             processed_input[col] = input_data.get(col, 0)
#         elif col == 'age':
#             processed_input[col] = np.log(float(input_data.get('age', 25.0)) + 1)
#         elif col == 'gender':
#             processed_input[col] = input_data.get('gender', 'unknown')
#         elif col == 'jaundice':
#             processed_input[col] = input_data.get('jaundice', 'no')
#         elif col == 'austim':
#             processed_input[col] = input_data.get('austim', 'no')
#         elif col == 'used_app_before':
#             processed_input[col] = input_data.get('used_app_before', 'no')
#         elif col == 'ethnicity':
#             processed_input[col] = input_data.get('ethnicity', 'unknown')
#         elif col == 'contry_of_res':
#             processed_input[col] = input_data.get('contry_of_res', 'unknown')
#         elif col == 'relation':
#             processed_input[col] = input_data.get('relation', 'unknown')
#         elif col == 'result':
#             processed_input[col] = float(input_data.get('result', 0.0))
#         elif col == 'ageGroup':
#             processed_input[col] = input_data.get('ageGroup', 'Young')
#         elif col == 'sum_score':
#             processed_input[col] = int(input_data.get('sum_score', 0))
#         elif col == 'ind':
#             processed_input[col] = int(input_data.get('ind', 0))
#         else:
#             # Default for any unexpected columns
#             processed_input[col] = 0
    
#     # Convert to DataFrame
#     full_df = pd.DataFrame([processed_input])
    
#     # Ensure correct column order
#     full_df = full_df[feature_columns]
    
#     # Label encoding for categorical variables
#     categorical_columns = full_df.select_dtypes(include=['object']).columns
#     for col in categorical_columns:
#         le = LabelEncoder()
#         full_df[col] = le.fit_transform(full_df[col].astype(str))
    
#     # Impute and scale
#     try:
#         imputer = SimpleImputer(strategy='mean')
#         df_imputed = imputer.fit_transform(full_df)
#         df_scaled = scaler.transform(df_imputed)
#         return df_scaled
#     except Exception as e:
#         st.error(f"Error in preprocessing: {e}")
#         st.error("Input data: " + str(input_data))
#         st.error("Processed DataFrame: " + str(full_df))
#         st.error("Feature Columns: " + str(feature_columns))
#         raise

# def main():
#     st.title('Autism Spectrum Disorder Prediction')
    
#     # Sidebar for model selection
#     st.sidebar.header('Model Selection')
#     model_choice = st.sidebar.selectbox(
#         'Choose a Model',
#         ['Logistic Regression', 'XGBoost', 'SVM']
#     )
    
#     # Load models
#     models, feature_columns, scaler = load_model()
    
#     # Create input fields dynamically based on feature columns
#     input_data = {}
    
#     # Divide inputs into columns for better layout
#     col1, col2 = st.columns(2)
    
#     with col1:
#         # Numeric inputs
#         input_data['age'] = st.number_input('Age', min_value=0.0, max_value=100.0, value=25.0)
#         input_data['result'] = st.number_input('Result', min_value=-5.0, max_value=100.0, value=0.0)
        
#         # Score inputs
#         for i in range(1, 6):
#             input_data[f'A{i}_Score'] = st.number_input(f'A{i} Score', min_value=0, max_value=10, value=0)
    
#     with col2:
#         # Categorical inputs
#         input_data['gender'] = st.selectbox('Gender', ['male', 'female'])
#         input_data['jaundice'] = st.selectbox('Jaundice', ['yes', 'no'])
#         input_data['austim'] = st.selectbox('Autism', ['yes', 'no'])
#         input_data['used_app_before'] = st.selectbox('Used App Before', ['yes', 'no'])
        
#         # Remaining score inputs
#         for i in range(6, 11):
#             input_data[f'A{i}_Score'] = st.number_input(f'A{i} Score', min_value=0, max_value=10, value=0)
    
#     # Additional feature engineering
#     input_data['sum_score'] = sum(input_data[f'A{i}_Score'] for i in range(1, 11))
#     input_data['ind'] = (1 if input_data['austim'] == 'yes' else 0) + \
#                         (1 if input_data['used_app_before'] == 'yes' else 0) + \
#                         (1 if input_data['jaundice'] == 'yes' else 0)
    
#     # Add ageGroup feature
#     def convertAge(age):
#         if age < 4:
#             return 'Toddler'
#         elif age < 12:
#             return 'Kid'
#         elif age < 18:
#             return 'Teenager'
#         elif age < 40:
#             return 'Young'
#         else:
#             return 'Senior'
    
#     input_data['ageGroup'] = convertAge(input_data['age'])
    
#     # Add visualization section
#     st.sidebar.header('Model Performance Visualization')
#     show_graphs = st.sidebar.checkbox('Show Training/Test Graphs')
    
#     if show_graphs:
#         st.header('Model Performance Analysis')
        
#         # Create tabs for different visualizations
#         tabs = st.tabs(['Model Comparison', 'Training vs Test', 'ROC Curves', 'Confusion Matrix'])
        
#         with tabs[0]:
#             st.subheader('Model Performance Comparison')
#             # This would show comparative metrics across all models
#             st.info("Model comparison visualization will be displayed here")
            
#         with tabs[1]:
#             st.subheader('Training vs Test Performance')
#             # Show training vs test accuracy/loss for selected model
#             col1, col2 = st.columns(2)
#             with col1:
#                 st.metric("Training Accuracy", "92.3%", "+2.1%")
#                 st.metric("Training AUC", "0.95", "+0.03")
#             with col2:
#                 st.metric("Test Accuracy", "89.7%", "-1.2%")
#                 st.metric("Test AUC", "0.91", "-0.02")
                
#             # Training vs Test Performance Chart
#             performance_data = {
#                 'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC'],
#                 'Training': [0.923, 0.915, 0.898, 0.906, 0.95],
#                 'Test': [0.897, 0.882, 0.875, 0.878, 0.91]
#             }
            
#             fig = go.Figure()
#             fig.add_trace(go.Bar(
#                 x=performance_data['Metric'],
#                 y=performance_data['Training'],
#                 name='Training',
#                 marker_color='lightblue'
#             ))
#             fig.add_trace(go.Bar(
#                 x=performance_data['Metric'],
#                 y=performance_data['Test'],
#                 name='Test',
#                 marker_color='lightcoral'
#             ))
#             fig.update_layout(
#                 title=f'{model_choice} - Training vs Test Performance',
#                 xaxis_title='Metrics',
#                 yaxis_title='Score',
#                 barmode='group'
#             )
#             st.plotly_chart(fig, use_container_width=True)
            
#         with tabs[2]:
#             st.subheader('ROC Curves')
#             # ROC Curve visualization
#             fpr, tpr, _ = roc_curve([0, 1, 1, 0, 1], [0.1, 0.8, 0.9, 0.2, 0.85])
#             roc_auc = auc(fpr, tpr)
            
#             fig = go.Figure()
#             fig.add_trace(go.Scatter(
#                 x=fpr, y=tpr,
#                 mode='lines',
#                 name=f'ROC curve (AUC = {roc_auc:.2f})',
#                 line=dict(color='darkorange', width=2)
#             ))
#             fig.add_trace(go.Scatter(
#                 x=[0, 1], y=[0, 1],
#                 mode='lines',
#                 name='Random Classifier',
#                 line=dict(color='navy', width=2, dash='dash')
#             ))
#             fig.update_layout(
#                 title=f'{model_choice} - ROC Curve',
#                 xaxis_title='False Positive Rate',
#                 yaxis_title='True Positive Rate',
#                 width=600,
#                 height=400
#             )
#             st.plotly_chart(fig, use_container_width=True)
            
#         with tabs[3]:
#             st.subheader('Confusion Matrix')
#             # Confusion matrix visualization
#             cm = [[45, 5], [8, 42]]  # Example confusion matrix
#             labels = ['No ASD', 'ASD']
            
#             fig = go.Figure(data=go.Heatmap(
#                 z=cm,
#                 x=labels,
#                 y=labels,
#                 colorscale='Blues',
#                 text=cm,
#                 texttemplate="%{text}",
#                 textfont={"size": 16}
#             ))
#             fig.update_layout(
#                 title=f'{model_choice} - Confusion Matrix',
#                 xaxis_title='Predicted',
#                 yaxis_title='Actual'
#             )
#             st.plotly_chart(fig, use_container_width=True)
    
#     # Prediction button
#     if st.button('Predict'):
#         # Preprocess input
#         processed_input = preprocess_input(input_data, feature_columns, scaler)
        
#         # Make prediction
#         model_pipeline = models[model_choice]
#         prediction = model_pipeline.predict(processed_input)
#         prediction_proba = model_pipeline.predict_proba(processed_input)
        
#         # Display results
#         st.subheader('Prediction Results')
#         if prediction[0] == 1:
#             st.error('Potential Autism Spectrum Disorder Detected')
#         else:
#             st.success('No Autism Spectrum Disorder Detected')
        
#         # Probability display
#         st.write(f'Probability of ASD: {prediction_proba[0][1]:.2%}')
#         st.write(f'Model Used: {model_choice}')

# if __name__ == '__main__':
#     main()
# # --- Helper: load models, feature columns and scaler ---
# def load_model():
#     models = {
#         'Logistic Regression': joblib.load('logistic_regression_model.joblib'),
#         'XGBoost': joblib.load('xgboost_model.joblib'),
#         'SVM': joblib.load('svm_model.joblib')
#     }
#     feature_columns = joblib.load('feature_columns.joblib')
#     scaler = joblib.load('feature_scaler.joblib')
#     return models, feature_columns, scaler

# # --- Preprocessing for single input ---
# def preprocess_input(input_data, feature_columns, scaler):
#     processed_input = {}
#     for col in feature_columns:
#         if col.startswith('A') and col.endswith('_Score'):
#             processed_input[col] = input_data.get(col, 0)
#         elif col == 'age':
#             processed_input[col] = np.log(float(input_data.get('age', 25.0)) + 1)
#         elif col == 'gender':
#             processed_input[col] = input_data.get('gender', 'unknown')
#         elif col == 'jaundice':
#             processed_input[col] = input_data.get('jaundice', 'no')
#         elif col == 'austim':
#             processed_input[col] = input_data.get('austim', 'no')
#         elif col == 'used_app_before':
#             processed_input[col] = input_data.get('used_app_before', 'no')
#         elif col == 'ethnicity':
#             processed_input[col] = input_data.get('ethnicity', 'unknown')
#         elif col == 'contry_of_res':
#             processed_input[col] = input_data.get('contry_of_res', 'unknown')
#         elif col == 'relation':
#             processed_input[col] = input_data.get('relation', 'unknown')
#         elif col == 'result':
#             processed_input[col] = float(input_data.get('result', 0.0))
#         elif col == 'ageGroup':
#             processed_input[col] = input_data.get('ageGroup', 'Young')
#         elif col == 'sum_score':
#             processed_input[col] = int(input_data.get('sum_score', 0))
#         elif col == 'ind':
#             processed_input[col] = int(input_data.get('ind', 0))
#         else:
#             processed_input[col] = 0

#     full_df = pd.DataFrame([processed_input])
#     full_df = full_df[feature_columns]

#     # Label encoding for categorical variables (note: this creates fresh mappings)
#     categorical_columns = full_df.select_dtypes(include=['object']).columns
#     for col in categorical_columns:
#         le = LabelEncoder()
#         full_df[col] = le.fit_transform(full_df[col].astype(str))

#     try:
#         imputer = SimpleImputer(strategy='mean')
#         df_imputed = imputer.fit_transform(full_df)
#         df_scaled = scaler.transform(df_imputed)
#         return df_scaled
#     except Exception as e:
#         st.error(f"Error in preprocessing: {e}")
#         st.error("Input data: " + str(input_data))
#         st.error("Processed DataFrame: " + str(full_df))
#         st.error("Feature Columns: " + str(feature_columns))
#         raise

# updated code
# --- Helper: load models, feature columns, scaler, and encoders ---
# app.py (updated)

# ---------------------
# Helpers: load models & assets
# ---------------------
# def load_model():
#     # load models (paths must match what train.py saved)
#     models = {
#         'Logistic Regression': joblib.load('logistic_regression_model.joblib'),
#         'XGBoost': joblib.load('xgboost_model.joblib'),
#         'SVM': joblib.load('svm_model.joblib')
#     }
#     feature_columns = joblib.load('feature_columns.joblib')  # this should be a list
#     scaler = joblib.load('feature_scaler.joblib')

#     # Load encoders safely
#     if os.path.exists('label_encoders.joblib'):
#         encoders = joblib.load('label_encoders.joblib')
#     elif os.path.exists('encoders.joblib'):
#         encoders = joblib.load('encoders.joblib')
#     else:
#         st.warning("⚠️ No label_encoders.joblib found. Categorical mappings may be approximate.")
#         encoders = {}

#     return models, feature_columns, scaler, encoders